{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "***\n",
    "\n",
    "# Regression-Based Model\n",
    "\n",
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Introduction\n",
    "<br>\n",
    "<b><big>Apprentice Chef, Inc.</big></b><br>\n",
    "A company that offers a wide selection of daily-prepared gourmet meals delivered directly to your door.<br>\n",
    "<br>\n",
    "<b><big>Context</big></b><br>\n",
    "Apprentice Chef, Inc. is attempting to understand how much revenue to expect from each customer within their first year of orders.<br>\n",
    "<br>\n",
    "<b><big>Dataset</big></b><br>\n",
    "The dataset (\"Apprentice_Chef_Dataset.xlsx\") in this script contains 29 different features of 1946 existing customers.\n",
    "\n",
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "\n",
    "# Set print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Apprentice_Chef_Data_Dictionary\n",
    "file1 = \"Apprentice_Chef_Data_Dictionary.xlsx\"\n",
    "dictionary = pd.read_excel(file1) \n",
    "\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Apprentice_Chef_Dataset\n",
    "file = \"Apprentice_Chef_Dataset.xlsx\"\n",
    "data = pd.read_excel(file)\n",
    "\n",
    "# Check the dataset\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1946 entries, 0 to 1945\n",
      "Data columns (total 29 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   REVENUE                       1946 non-null   float64\n",
      " 1   CROSS_SELL_SUCCESS            1946 non-null   int64  \n",
      " 2   NAME                          1946 non-null   object \n",
      " 3   EMAIL                         1946 non-null   object \n",
      " 4   FIRST_NAME                    1946 non-null   object \n",
      " 5   FAMILY_NAME                   1899 non-null   object \n",
      " 6   TOTAL_MEALS_ORDERED           1946 non-null   int64  \n",
      " 7   UNIQUE_MEALS_PURCH            1946 non-null   int64  \n",
      " 8   CONTACTS_W_CUSTOMER_SERVICE   1946 non-null   int64  \n",
      " 9   PRODUCT_CATEGORIES_VIEWED     1946 non-null   int64  \n",
      " 10  AVG_TIME_PER_SITE_VISIT       1946 non-null   float64\n",
      " 11  MOBILE_NUMBER                 1946 non-null   int64  \n",
      " 12  CANCELLATIONS_BEFORE_NOON     1946 non-null   int64  \n",
      " 13  CANCELLATIONS_AFTER_NOON      1946 non-null   int64  \n",
      " 14  TASTES_AND_PREFERENCES        1946 non-null   int64  \n",
      " 15  PC_LOGINS                     1946 non-null   int64  \n",
      " 16  MOBILE_LOGINS                 1946 non-null   int64  \n",
      " 17  WEEKLY_PLAN                   1946 non-null   int64  \n",
      " 18  EARLY_DELIVERIES              1946 non-null   int64  \n",
      " 19  LATE_DELIVERIES               1946 non-null   int64  \n",
      " 20  PACKAGE_LOCKER                1946 non-null   int64  \n",
      " 21  REFRIGERATED_LOCKER           1946 non-null   int64  \n",
      " 22  FOLLOWED_RECOMMENDATIONS_PCT  1946 non-null   int64  \n",
      " 23  AVG_PREP_VID_TIME             1946 non-null   float64\n",
      " 24  LARGEST_ORDER_SIZE            1946 non-null   int64  \n",
      " 25  MASTER_CLASSES_ATTENDED       1946 non-null   int64  \n",
      " 26  MEDIAN_MEAL_RATING            1946 non-null   int64  \n",
      " 27  AVG_CLICKS_PER_VISIT          1946 non-null   int64  \n",
      " 28  TOTAL_PHOTOS_VIEWED           1946 non-null   int64  \n",
      "dtypes: float64(3), int64(22), object(4)\n",
      "memory usage: 441.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REVENUE</th>\n",
       "      <th>CROSS_SELL_SUCCESS</th>\n",
       "      <th>TOTAL_MEALS_ORDERED</th>\n",
       "      <th>UNIQUE_MEALS_PURCH</th>\n",
       "      <th>CONTACTS_W_CUSTOMER_SERVICE</th>\n",
       "      <th>PRODUCT_CATEGORIES_VIEWED</th>\n",
       "      <th>AVG_TIME_PER_SITE_VISIT</th>\n",
       "      <th>MOBILE_NUMBER</th>\n",
       "      <th>CANCELLATIONS_BEFORE_NOON</th>\n",
       "      <th>CANCELLATIONS_AFTER_NOON</th>\n",
       "      <th>TASTES_AND_PREFERENCES</th>\n",
       "      <th>PC_LOGINS</th>\n",
       "      <th>MOBILE_LOGINS</th>\n",
       "      <th>WEEKLY_PLAN</th>\n",
       "      <th>EARLY_DELIVERIES</th>\n",
       "      <th>LATE_DELIVERIES</th>\n",
       "      <th>PACKAGE_LOCKER</th>\n",
       "      <th>REFRIGERATED_LOCKER</th>\n",
       "      <th>FOLLOWED_RECOMMENDATIONS_PCT</th>\n",
       "      <th>AVG_PREP_VID_TIME</th>\n",
       "      <th>LARGEST_ORDER_SIZE</th>\n",
       "      <th>MASTER_CLASSES_ATTENDED</th>\n",
       "      <th>MEDIAN_MEAL_RATING</th>\n",
       "      <th>AVG_CLICKS_PER_VISIT</th>\n",
       "      <th>TOTAL_PHOTOS_VIEWED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2107.29</td>\n",
       "      <td>0.68</td>\n",
       "      <td>74.63</td>\n",
       "      <td>4.9</td>\n",
       "      <td>6.98</td>\n",
       "      <td>5.38</td>\n",
       "      <td>99.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.71</td>\n",
       "      <td>5.52</td>\n",
       "      <td>1.48</td>\n",
       "      <td>11.33</td>\n",
       "      <td>1.49</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.11</td>\n",
       "      <td>35.41</td>\n",
       "      <td>150.56</td>\n",
       "      <td>4.44</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.79</td>\n",
       "      <td>13.51</td>\n",
       "      <td>106.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1138.29</td>\n",
       "      <td>0.47</td>\n",
       "      <td>55.31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.28</td>\n",
       "      <td>3.04</td>\n",
       "      <td>62.34</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.53</td>\n",
       "      <td>13.57</td>\n",
       "      <td>2.32</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.32</td>\n",
       "      <td>26.58</td>\n",
       "      <td>49.45</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2.33</td>\n",
       "      <td>181.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>131.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1350.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>72.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>114.40</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1740.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>94.16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>145.60</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2670.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>95.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>117.29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>173.78</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>174.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8793.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>493.00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1645.60</td>\n",
       "      <td>1.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>52.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>564.20</td>\n",
       "      <td>11.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>1600.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       REVENUE  CROSS_SELL_SUCCESS  TOTAL_MEALS_ORDERED  UNIQUE_MEALS_PURCH  CONTACTS_W_CUSTOMER_SERVICE  PRODUCT_CATEGORIES_VIEWED  AVG_TIME_PER_SITE_VISIT  MOBILE_NUMBER  CANCELLATIONS_BEFORE_NOON  CANCELLATIONS_AFTER_NOON  TASTES_AND_PREFERENCES  PC_LOGINS  MOBILE_LOGINS  WEEKLY_PLAN  EARLY_DELIVERIES  LATE_DELIVERIES  PACKAGE_LOCKER  REFRIGERATED_LOCKER  FOLLOWED_RECOMMENDATIONS_PCT  AVG_PREP_VID_TIME  LARGEST_ORDER_SIZE  MASTER_CLASSES_ATTENDED  MEDIAN_MEAL_RATING  AVG_CLICKS_PER_VISIT  TOTAL_PHOTOS_VIEWED\n",
       "count  1946.00             1946.00              1946.00              1946.0                      1946.00                    1946.00                  1946.00        1946.00                    1946.00                   1946.00                 1946.00    1946.00        1946.00      1946.00           1946.00          1946.00         1946.00              1946.00                       1946.00            1946.00             1946.00                  1946.00             1946.00               1946.00              1946.00\n",
       "mean   2107.29                0.68                74.63                 4.9                         6.98                       5.38                    99.60           0.88                       1.40                      0.17                    0.71       5.52           1.48        11.33              1.49             2.97            0.36                 0.11                         35.41             150.56                4.44                     0.60                2.79                 13.51               106.43\n",
       "std    1138.29                0.47                55.31                 2.5                         2.28                       3.04                    62.34           0.33                       1.55                      0.43                    0.45       0.58           0.53        13.57              2.32             2.74            0.48                 0.32                         26.58              49.45                1.55                     0.64                0.76                  2.33               181.01\n",
       "min     131.00                0.00                11.00                 1.0                         1.00                       1.00                    10.33           0.00                       0.00                      0.00                    0.00       4.00           0.00         0.00              0.00             0.00            0.00                 0.00                          0.00              33.40                0.00                     0.00                1.00                  5.00                 0.00\n",
       "25%    1350.00                0.00                39.00                 3.0                         5.00                       3.00                    72.00           1.00                       0.00                      0.00                    0.00       5.00           1.00         1.00              0.00             1.00            0.00                 0.00                         10.00             114.40                3.00                     0.00                2.00                 12.00                 0.00\n",
       "50%    1740.00                1.00                60.00                 5.0                         7.00                       5.00                    94.16           1.00                       1.00                      0.00                    1.00       6.00           1.00         7.00              0.00             2.00            0.00                 0.00                         30.00             145.60                4.00                     1.00                3.00                 13.00                 0.00\n",
       "75%    2670.00                1.00                95.00                 7.0                         8.00                       8.00                   117.29           1.00                       2.00                      0.00                    1.00       6.00           2.00        13.00              3.00             4.00            1.00                 0.00                         60.00             173.78                5.00                     1.00                3.00                 15.00               174.00\n",
       "max    8793.75                1.00               493.00                19.0                        18.00                      10.00                  1645.60           1.00                      13.00                      3.00                    1.00       7.00           3.00        52.00              9.00            19.00            1.00                 1.00                         90.00             564.20               11.00                     3.00                5.00                 19.00              1600.00"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go through basic info about the dataset to capture the big picture\n",
    "data.info()\n",
    "data.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<big>NOTE</big>\n",
    "- there are 47 missing values in \"FAMILY_NAME\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<b> Create a new column called \"price_per_meal\"</b><br>\n",
    "Since how much each customer has paid for each meal is unknonwn, I simply divide the total revenue from each customer (\"REVENUE\") by the total number of meals he/she has ordered (\"TOTAL_MEALS_ORDERED\") to see how much each meal roughly represents. I named this new feature called \"price_per_meal\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new variable called 'price_per_meal'\n",
    "PRICE = data['REVENUE'] / data['TOTAL_MEALS_ORDERED']\n",
    "\n",
    "PRICE = PRICE.round(2)\n",
    "\n",
    "data['price_per_meal'] = PRICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<b>Creating a new column called \"email_domain\"</b><br>\n",
    "- I will explore if there are any significant factors/ findings between different types of email domails (e.g. gmail, yahoo etc.)\n",
    "- I will categorize those domains into four groups: professional, personal, junk, and unknown based on the information given from Apprentice Chef\n",
    "- Then I will convert it into a numerical variable \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split personal emails\n",
    "email_list = []\n",
    "\n",
    "# looping over each email address\n",
    "for index, col in data.iterrows():\n",
    "    \n",
    "    # splitting email domain at '@'\n",
    "    split_email = data.loc[index, 'EMAIL'].split(sep = '@')\n",
    "   \n",
    "    # appending placeholder_lst with the results\n",
    "    email_list.append(split_email)\n",
    "    \n",
    "\n",
    "# Convert 'email_list' into a DataFrame \n",
    "email_df = pd.DataFrame(email_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes the name of columns \n",
    "email_df.columns = ['name', 'email_domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatinates 'email_domain' to our dataframe 'data'\n",
    "data = pd.concat([data, email_df['email_domain']], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Email domain types\n",
    "professional_email_domains = ['@mmm.com', '@amex.com', '@apple.com', '@boeing.com',\n",
    "                              '@caterpillar.com', '@chevron.com', '@cisco.com', '@cocacola.com',\n",
    "                              '@disney.com', '@dupont.com', '@exxon.com', '@ge.org',\n",
    "                              '@goldmansacs.com', '@homedepot.com', '@ibm.com', '@intel.com',\n",
    "                              '@jnj.com', '@jpmorgan.com', '@mcdonalds.com', '@merck.com',\n",
    "                              '@microsoft.com', '@nike.com', '@pfizer.com', '@pg.com', '@travelers.com',\n",
    "                              '@unitedhealth.com', '@verizon.com', '@visa.com', '@walmart.com']\n",
    "\n",
    "personal_email_domains  = ['@gmail.com', '@yahoo.com', '@protonmail.com']\n",
    "\n",
    "junk_email_domains = ['@me.com', '@aol.com', '@hotmail.com',\n",
    "                      '@live.com','@msn.com', '@passport.com']\n",
    "\n",
    "domain_type_list = []\n",
    "\n",
    "# loop to group observations by domain type\n",
    "\n",
    "for domain in data['email_domain']:\n",
    "        if '@' + domain in professional_email_domains:\n",
    "            domain_type_list.append('professional')\n",
    "            \n",
    "        elif '@' + domain in personal_email_domains:\n",
    "            domain_type_list.append('personal')\n",
    "        \n",
    "        elif '@' + domain in junk_email_domains:\n",
    "            domain_type_list.append('junk')\n",
    "            \n",
    "        else:\n",
    "            domain_type_list.append('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate with original DataFrame\n",
    "data['domain_type'] = pd.Series(domain_type_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dummy variables for 'domain_type'\n",
    "data = pd.get_dummies(data, prefix_sep='__', columns=['domain_type'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'email_domain' from 'data' because I converted it into dummy variables \n",
    "data = data.drop(['email_domain'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute 'NaN' in 'FAMILY_NAME' as 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputed 'Unknown' to 47 NaNs in 'FAMILY_NAME'\n",
    "data['FAMILY_NAME'] = data['FAMILY_NAME'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Feature Engineering 1\n",
    "Here, I used these following steps to transform the data into features that represent underlying changes in all explanatory variables.<br>\n",
    "<br>\n",
    "<b>Step 1.</b> Plotting histograms of the exploratory variables to to see if there are any noticable changing points<br>\n",
    "<b>Step 2.</b> Set outlier thresholds for those changing points<br>\n",
    "<b>Step 3.</b> Create new columns of those variables with outlier flags | 1 = outlier  0 = not flagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Plot Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# subplot(2,2,1) means you choose 1 out of 2 * 2\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.distplot(data['REVENUE'],\n",
    "             bins  = 'fd',\n",
    "             color = 'g')\n",
    "plt.xlabel('REVENUE')\n",
    "\n",
    "#####\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.distplot(data['CROSS_SELL_SUCCESS'],\n",
    "             bins  = 'fd',\n",
    "             color = 'y')\n",
    "plt.xlabel('CROSS_SELL_SUCCESS')\n",
    "\n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.distplot(data['TOTAL_MEALS_ORDERED'],\n",
    "             bins  = 'fd',\n",
    "             kde   = True,\n",
    "             rug   = True,\n",
    "             color = 'orange')\n",
    "plt.xlabel('TOTAL_MEALS_ORDERED')\n",
    "\n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.distplot(data['UNIQUE_MEALS_PURCH'],\n",
    "             bins  = 'fd',\n",
    "             kde   = True,\n",
    "             rug   = True,\n",
    "             color = 'r')\n",
    "plt.xlabel('UNIQUE_MEALS_PURCH')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Housing Data Histograms 1 of 5.png')\n",
    "plt.show()\n",
    "\n",
    "#####\n",
    "#####\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.distplot(data['CONTACTS_W_CUSTOMER_SERVICE'],\n",
    "             bins  = 'fd',\n",
    "             color = 'g')\n",
    "plt.xlabel('CONTACTS_W_CUSTOMER_SERVICE')\n",
    "\n",
    "#####\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.distplot(data['PRODUCT_CATEGORIES_VIEWED'],\n",
    "             bins  = 'fd',\n",
    "             color = 'y')\n",
    "plt.xlabel('PRODUCT_CATEGORIES_VIEWED')\n",
    "\n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.distplot(data['AVG_TIME_PER_SITE_VISIT'],\n",
    "             bins  = 'fd',\n",
    "             kde   = True,\n",
    "             rug   = True,\n",
    "             color = 'orange')\n",
    "plt.xlabel('AVG_TIME_PER_SITE_VISIT')\n",
    "\n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.distplot(data['CANCELLATIONS_BEFORE_NOON'],\n",
    "             bins  = 'fd',\n",
    "             kde   = True,\n",
    "             rug   = True,\n",
    "             color = 'r')\n",
    "plt.xlabel('CANCELLATIONS_BEFORE_NOON')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Housing Data Histograms 2 of 5.png')\n",
    "plt.show()\n",
    "\n",
    "#####\n",
    "#####\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.distplot(data['CANCELLATIONS_AFTER_NOON'],\n",
    "             #bins  = 'fd',\n",
    "             kde = False,\n",
    "             rug = True,\n",
    "             color = 'g')\n",
    "plt.xlabel('CANCELLATIONS_AFTER_NOON')\n",
    "\n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.distplot(data['TASTES_AND_PREFERENCES'],\n",
    "             bins  = 'fd',\n",
    "             kde   = True,\n",
    "             rug   = True,\n",
    "             color = 'y')\n",
    "plt.xlabel('TASTES_AND_PREFERENCES')\n",
    "\n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.distplot(data['PC_LOGINS'],\n",
    "             bins  = 'fd',\n",
    "             kde   = True,\n",
    "             rug   = True,\n",
    "             color = 'orange')\n",
    "plt.xlabel('PC_LOGINS')\n",
    "\n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.distplot(data['MOBILE_LOGINS'],\n",
    "             bins  = 'fd',\n",
    "             color = 'r')\n",
    "plt.xlabel('MOBILE_LOGINS')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Housing Data Histograms 3 of 5.png')\n",
    "plt.show()\n",
    "\n",
    "#####\n",
    "#####\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.distplot(data['WEEKLY_PLAN'],\n",
    "             bins  = 'fd',\n",
    "             color = 'g')\n",
    "plt.xlabel('WEEKLY_PLAN')\n",
    "\n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.distplot(data['EARLY_DELIVERIES'],\n",
    "             bins = 10,\n",
    "             kde  = True,\n",
    "             rug  = True,\n",
    "             color = 'y')\n",
    "plt.xlabel('EARLY_DELIVERIES')\n",
    "\n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.distplot(data['LATE_DELIVERIES'],\n",
    "             bins = 'fd',\n",
    "             kde  = True,\n",
    "             rug  = True,\n",
    "             color = 'orange')\n",
    "plt.xlabel('LATE_DELIVERIES')\n",
    "\n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.distplot(data['PACKAGE_LOCKER'],\n",
    "             bins  = 'fd',\n",
    "             color = 'r')\n",
    "plt.xlabel('PACKAGE_LOCKER')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Housing Data Histograms 4 of 5.png')\n",
    "plt.show()\n",
    "\n",
    "#####\n",
    "#####\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.distplot(data['REFRIGERATED_LOCKER'],\n",
    "             #bins  = 5,\n",
    "             kde   = False,\n",
    "             rug   = True,\n",
    "             color = 'g')\n",
    "plt.xlabel('REFRIGERATED_LOCKER')\n",
    "\n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.distplot(data['FOLLOWED_RECOMMENDATIONS_PCT'],\n",
    "             bins  = 'fd',\n",
    "             kde   = True,\n",
    "             rug   = True,\n",
    "             color = 'y')\n",
    "plt.xlabel('FOLLOWED_RECOMMENDATIONS_PCT')\n",
    "\n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.distplot(data['AVG_PREP_VID_TIME'],\n",
    "           bins = 'fd', \n",
    "           kde = True,\n",
    "           rug = True,\n",
    "           color = 'orange')\n",
    "plt.xlabel('AVG_PREP_VID_TIME')\n",
    "\n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.distplot(data['LARGEST_ORDER_SIZE'],\n",
    "           bins = 'fd', \n",
    "           kde = True,\n",
    "           rug = True,\n",
    "           color = 'r')\n",
    "plt.xlabel('LARGEST_ORDER_SIZE')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#####\n",
    "#####\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.distplot(data['MASTER_CLASSES_ATTENDED'],\n",
    "           bins = 'fd', \n",
    "           kde = True,\n",
    "           rug = True,\n",
    "           color = 'g')\n",
    "plt.xlabel('MASTER_CLASSES_ATTENDED')\n",
    "\n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.distplot(data['MEDIAN_MEAL_RATING'],\n",
    "           bins = 'fd', \n",
    "           kde = True,\n",
    "           rug = True,\n",
    "           color = 'y')\n",
    "plt.xlabel('MEDIAN_MEAL_RATING')\n",
    "\n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.distplot(data['AVG_CLICKS_PER_VISIT'],\n",
    "           bins = 'fd', \n",
    "           kde = True,\n",
    "           rug = True,\n",
    "           color = 'orange')\n",
    "plt.xlabel('AVG_CLICKS_PER_VISIT')\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.distplot(data['TOTAL_PHOTOS_VIEWED'],\n",
    "           bins = 'fd', \n",
    "           kde = True,\n",
    "           rug = True,\n",
    "           color = 'r')\n",
    "plt.xlabel('TOTAL_PHOTOS_VIEWED')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#####\n",
    "#####\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.distplot(data['price_per_meal'],\n",
    "           bins = 'fd', \n",
    "           kde = True,\n",
    "           rug = True,\n",
    "           color = 'g')\n",
    "plt.xlabel('PRICE_PER_MEAL')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : Set outlier thresholds using 0.95-quantile for high and 0.05-quantile for low points\n",
    "NOTE : 0.95-quantile for high and 0.05=quantile for low points mean that I flagged those customers above the rest of 5% (= 0.95-quantile) and those below 5% (= 0.05-quantile) as outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_REVENUE_hi = 2200\n",
    "out_TOTAL_MEALS_ORDERED_hi = data['TOTAL_MEALS_ORDERED'].quantile(0.95)\n",
    "out_UNIQUE_MEALS_PURCH_hi = data['UNIQUE_MEALS_PURCH'].quantile(0.95)\n",
    "out_CONTACTS_W_CUSTOMER_SERVICE_lo = data['CONTACTS_W_CUSTOMER_SERVICE'].quantile(0.05)\n",
    "out_CONTACTS_W_CUSTOMER_SERVICE_hi = data['CONTACTS_W_CUSTOMER_SERVICE'].quantile(0.95)\n",
    "out_AVG_TIME_PER_SITE_VISIT_hi = data['AVG_TIME_PER_SITE_VISIT'].quantile(0.95)\n",
    "out_CANCELLATIONS_BEFORE_NOON_hi = data['CANCELLATIONS_BEFORE_NOON'].quantile(0.95)\n",
    "out_CANCELLATIONS_AFTER_NOON_hi = data['CANCELLATIONS_AFTER_NOON'].quantile(0.95)\n",
    "out_PC_LOGINS_lo = data['PC_LOGINS'].quantile(0.05)\n",
    "out_PC_LOGINS_hi = data['PC_LOGINS'].quantile(0.95)\n",
    "out_MOBILE_LOGINS_lo = data['MOBILE_LOGINS'].quantile(0.05)\n",
    "out_MOBILE_LOGINS_hi = data['MOBILE_LOGINS'].quantile(0.95)\n",
    "out_WEEKLY_PLAN_hi  = data['WEEKLY_PLAN'].quantile(0.95)\n",
    "out_EARLY_DELIVERIES_hi = data['EARLY_DELIVERIES'].quantile(0.95)\n",
    "out_LATE_DELIVERIES_hi = data['LATE_DELIVERIES'].quantile(0.95)\n",
    "out_FOLLOWED_RECOMMENDATIONS_PCT_lo = data['FOLLOWED_RECOMMENDATIONS_PCT'].quantile(0.05)\n",
    "out_FOLLOWED_RECOMMENDATIONS_PCT_hi = data['FOLLOWED_RECOMMENDATIONS_PCT'].quantile(0.95)\n",
    "out_MASTER_CLASSES_ATTENDED_hi = data['MASTER_CLASSES_ATTENDED'].quantile(0.95)\n",
    "out_MEDIAN_MEAL_RATING_lo = data['MEDIAN_MEAL_RATING'].quantile(0.05)\n",
    "out_MEDIAN_MEAL_RATING_hi = data['MEDIAN_MEAL_RATING'].quantile(0.95)\n",
    "out_AVG_PREP_VID_TIME_hi = data['AVG_PREP_VID_TIME'].quantile(0.95)\n",
    "out_LARGEST_ORDER_SIZE_lo = data['LARGEST_ORDER_SIZE'].quantile(0.05)\n",
    "out_LARGEST_ORDER_SIZE_hi = data['LARGEST_ORDER_SIZE'].quantile(0.95)\n",
    "out_AVG_CLICKS_PER_VISIT_lo = data['AVG_CLICKS_PER_VISIT'].quantile(0.05)\n",
    "out_AVG_CLICKS_PER_VISIT_hi = data['AVG_CLICKS_PER_VISIT'].quantile(0.95)\n",
    "out_TOTAL_PHOTOS_VIEWED_hi = data['TOTAL_PHOTOS_VIEWED'].quantile(0.95)\n",
    "out_PRICE_PER_MEAL_hi = data['price_per_meal'].quantile(0.95)\n",
    "out_REFRIGERATED_LOCKER_hi = data['REFRIGERATED_LOCKER'].quantile(0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : Create new columns of explanaotry variables with outlier flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REVENUE\n",
    "data['out_REVENUE'] = 0\n",
    "condition_hi = data.loc[0:,'out_REVENUE'][data['REVENUE'] > out_REVENUE_hi]\n",
    "\n",
    "data['out_REVENUE'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "\n",
    "# TOTAL_MEALS_ORDERED\n",
    "data['out_TOTAL_MEALS_ORDERED'] = 0\n",
    "condition_hi = data.loc[0:,'out_TOTAL_MEALS_ORDERED'][data['TOTAL_MEALS_ORDERED'] > out_TOTAL_MEALS_ORDERED_hi]\n",
    "\n",
    "data['out_TOTAL_MEALS_ORDERED'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# CONTACTS_W_CUSTOMER_SERVICE\n",
    "data['out_CONTACTS_W_CUSTOMER_SERVICE'] = 0\n",
    "condition_hi = data.loc[0:,'out_CONTACTS_W_CUSTOMER_SERVICE'][data['CONTACTS_W_CUSTOMER_SERVICE'] > out_CONTACTS_W_CUSTOMER_SERVICE_hi]\n",
    "condition_lo = data.loc[0:,'out_CONTACTS_W_CUSTOMER_SERVICE'][data['CONTACTS_W_CUSTOMER_SERVICE'] < out_CONTACTS_W_CUSTOMER_SERVICE_lo]\n",
    "\n",
    "data['out_CONTACTS_W_CUSTOMER_SERVICE'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "data['out_CONTACTS_W_CUSTOMER_SERVICE'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# AVG_TIME_PER_SITE_VISIT\n",
    "data['out_AVG_TIME_PER_SITE_VISIT'] = 0\n",
    "condition_hi = data.loc[0:,'out_AVG_TIME_PER_SITE_VISIT'][data['AVG_TIME_PER_SITE_VISIT'] > out_AVG_TIME_PER_SITE_VISIT_hi]\n",
    "\n",
    "data['out_AVG_TIME_PER_SITE_VISIT'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# CANCELLATIONS_BEFORE_NOON\n",
    "data['out_CANCELLATIONS_BEFORE_NOON'] = 0\n",
    "condition_hi = data.loc[0:,'out_CANCELLATIONS_BEFORE_NOON'][data['CANCELLATIONS_BEFORE_NOON'] > out_CANCELLATIONS_BEFORE_NOON_hi]\n",
    "\n",
    "data['out_CANCELLATIONS_BEFORE_NOON'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# CANCELLATIONS_AFTER_NOON\n",
    "data['out_CANCELLATIONS_AFTER_NOON'] = 0\n",
    "condition_hi = data.loc[0:,'out_CANCELLATIONS_AFTER_NOON'][data['CANCELLATIONS_AFTER_NOON'] > out_CANCELLATIONS_AFTER_NOON_hi]\n",
    "\n",
    "data['out_CANCELLATIONS_AFTER_NOON'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# PC_LOGINS\n",
    "data['out_PC_LOGINS'] = 0\n",
    "condition_hi = data.loc[0:,'out_PC_LOGINS'][data['PC_LOGINS'] > out_PC_LOGINS_hi]\n",
    "\n",
    "data['out_PC_LOGINS'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# MOBILE_LOGINS \n",
    "data['out_MOBILE_LOGINS'] = 0\n",
    "condition_hi = data.loc[0:,'out_MOBILE_LOGINS'][data['MOBILE_LOGINS'] > out_MOBILE_LOGINS_hi]\n",
    "condition_lo = data.loc[0:,'out_MOBILE_LOGINS'][data['MOBILE_LOGINS'] < out_MOBILE_LOGINS_lo]\n",
    "\n",
    "data['out_MOBILE_LOGINS'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "data['out_MOBILE_LOGINS'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# WEEKLY_PLAN\n",
    "data['out_WEEKLY_PLAN'] = 0\n",
    "condition_hi = data.loc[0:,'out_WEEKLY_PLAN'][data['WEEKLY_PLAN'] > out_WEEKLY_PLAN_hi]\n",
    "\n",
    "data['out_WEEKLY_PLAN'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# EARLY_DELIVERIES\n",
    "data['out_EARLY_DELIVERIES'] = 0\n",
    "condition_hi = data.loc[0:,'out_EARLY_DELIVERIES'][data['EARLY_DELIVERIES'] > out_EARLY_DELIVERIES_hi]\n",
    "\n",
    "data['out_EARLY_DELIVERIES'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# LATE_DELIVERIES\n",
    "data['out_LATE_DELIVERIES'] = 0\n",
    "condition_hi = data.loc[0:,'out_LATE_DELIVERIES'][data['LATE_DELIVERIES'] > out_LATE_DELIVERIES_hi]\n",
    "\n",
    "data['out_LATE_DELIVERIES'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "\n",
    "# FOLLOWED_RECOMMENDATIONS_PCT \n",
    "data['out_FOLLOWED_RECOMMENDATIONS_PCT'] = 0\n",
    "condition_hi = data.loc[0:,'out_FOLLOWED_RECOMMENDATIONS_PCT'][data['FOLLOWED_RECOMMENDATIONS_PCT'] > out_FOLLOWED_RECOMMENDATIONS_PCT_hi]\n",
    "condition_lo = data.loc[0:,'out_FOLLOWED_RECOMMENDATIONS_PCT'][data['FOLLOWED_RECOMMENDATIONS_PCT'] < out_FOLLOWED_RECOMMENDATIONS_PCT_lo]\n",
    "\n",
    "data['out_FOLLOWED_RECOMMENDATIONS_PCT'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "data['out_FOLLOWED_RECOMMENDATIONS_PCT'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# MASTER_CLASSES_ATTENDED \n",
    "data['out_MASTER_CLASSES_ATTENDED'] = 0\n",
    "condition_hi = data.loc[0:,'out_MASTER_CLASSES_ATTENDED'][data['MASTER_CLASSES_ATTENDED'] > out_MASTER_CLASSES_ATTENDED_hi]\n",
    "\n",
    "data['out_MASTER_CLASSES_ATTENDED'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# MEDIAN_MEAL_RATING b\n",
    "data['out_MEDIAN_MEAL_RATING'] = 0\n",
    "condition_hi = data.loc[0:,'out_MEDIAN_MEAL_RATING'][data['MEDIAN_MEAL_RATING'] > out_MEDIAN_MEAL_RATING_hi]\n",
    "condition_lo = data.loc[0:,'out_MEDIAN_MEAL_RATING'][data['MEDIAN_MEAL_RATING'] < out_MEDIAN_MEAL_RATING_lo]\n",
    "\n",
    "data['out_MEDIAN_MEAL_RATING'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "data['out_MEDIAN_MEAL_RATING'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# AVG_PREP_VID_TIME\n",
    "data['out_AVG_PREP_VID_TIME'] = 0\n",
    "condition_hi = data.loc[0:,'out_AVG_PREP_VID_TIME'][data['AVG_PREP_VID_TIME'] > out_AVG_PREP_VID_TIME_hi]\n",
    "\n",
    "data['out_AVG_PREP_VID_TIME'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# LARGEST_ORDER_SIZE\n",
    "data['out_LARGEST_ORDER_SIZE'] = 0\n",
    "condition_hi = data.loc[0:,'out_LARGEST_ORDER_SIZE'][data['LARGEST_ORDER_SIZE'] > out_LARGEST_ORDER_SIZE_hi]\n",
    "condition_lo = data.loc[0:,'out_LARGEST_ORDER_SIZE'][data['LARGEST_ORDER_SIZE'] < out_LARGEST_ORDER_SIZE_lo]\n",
    "\n",
    "data['out_LARGEST_ORDER_SIZE'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "data['out_LARGEST_ORDER_SIZE'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# AVG_CLICKS_PER_VISIT\n",
    "data['out_AVG_CLICKS_PER_VISIT'] = 0\n",
    "condition_hi = data.loc[0:,'out_AVG_CLICKS_PER_VISIT'][data['AVG_CLICKS_PER_VISIT'] > out_AVG_CLICKS_PER_VISIT_hi]\n",
    "condition_lo = data.loc[0:,'out_AVG_CLICKS_PER_VISIT'][data['AVG_CLICKS_PER_VISIT'] < out_AVG_CLICKS_PER_VISIT_lo]\n",
    "\n",
    "data['out_AVG_CLICKS_PER_VISIT'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "data['out_AVG_CLICKS_PER_VISIT'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# TOTAL_PHOTOS_VIEWED\n",
    "data['out_TOTAL_PHOTOS_VIEWED'] = 0\n",
    "condition_hi = data.loc[0:,'out_TOTAL_PHOTOS_VIEWED'][data['TOTAL_PHOTOS_VIEWED'] > out_TOTAL_PHOTOS_VIEWED_hi]\n",
    "\n",
    "data['out_TOTAL_PHOTOS_VIEWED'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# PRICE_PER_MEAL\n",
    "data['out_PRICE_PER_MEAL'] = 0\n",
    "condition_hi = data.loc[0:,'out_PRICE_PER_MEAL'][data['price_per_meal'] > out_PRICE_PER_MEAL_hi]\n",
    "\n",
    "data['out_PRICE_PER_MEAL'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "# REFRIGERATE_LOCKER\n",
    "data['out_REFRIGERATED_LOCKER'] = 0\n",
    "condition_hi = data.loc[0:,'out_REFRIGERATED_LOCKER'][data['REFRIGERATED_LOCKER'] >= out_REFRIGERATED_LOCKER_hi]\n",
    "\n",
    "data['out_REFRIGERATED_LOCKER'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering 2\n",
    "Here, I used the following steps to identify where a variable's trend changes in terms of its relationship with what to predict (in this case, REVENUE).<br>\n",
    "<br>\n",
    "<b>Step 1.</b> Use scatter plot to see any trend changes<br>\n",
    "<b>Step 2.</b> Set trend-based thresholds to flag the changes<br>\n",
    "<b>Step 3.</b> Create new columns with trend flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Use Scatter Plot in the Relationship between Each Variable and Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3,
     19,
     26,
     38,
     46,
     54,
     62,
     74,
     82,
     90,
     98,
     110,
     118,
     126,
     134,
     147,
     155,
     163,
     171,
     184,
     192,
     200
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.scatterplot(x = data['CROSS_SELL_SUCCESS'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'g')\n",
    "plt.xlabel('CROSS SELL SUCCESS')\n",
    "\n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.scatterplot(x = data['TOTAL_MEALS_ORDERED'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'y')\n",
    "plt.xlabel('TOTAL MEALS ORDERED')\n",
    "\n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.scatterplot(x = data['UNIQUE_MEALS_PURCH'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'orange')\n",
    "plt.xlabel('UNIQUE MEALS PURCH')\n",
    "\n",
    "#####\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.scatterplot(x = data['CONTACTS_W_CUSTOMER_SERVICE'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'r')\n",
    "plt.xlabel('CONTACTS WITH CUSTOMER SERVICE')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#####\n",
    "#####\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.scatterplot(x = data['PRODUCT_CATEGORIES_VIEWED'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'g')\n",
    "plt.xlabel('PRODUCT CATEGORIES VIEWED')\n",
    "\n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.scatterplot(x = data['AVG_TIME_PER_SITE_VISIT'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'y')\n",
    "plt.xlabel('AVG TIME PER SITE VISIT')\n",
    "\n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.scatterplot(x = data['MOBILE_NUMBER'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'orange')\n",
    "plt.xlabel('MOBILE NUMBER')\n",
    "\n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.scatterplot(x = data['CANCELLATIONS_BEFORE_NOON'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'r')\n",
    "plt.xlabel('CANCELLATIONS BEFORE NOON')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#####\n",
    "#####\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.scatterplot(x = data['CANCELLATIONS_AFTER_NOON'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'y')\n",
    "plt.xlabel('CANCELLATIONS BEFORE NOON')\n",
    "\n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.scatterplot(x = data['TASTES_AND_PREFERENCES'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'orange')\n",
    "plt.xlabel('TASTES AND PREFERENCES')\n",
    "\n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.scatterplot(x = data['PC_LOGINS'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'r')\n",
    "plt.xlabel('PC LOGINS')\n",
    "\n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.scatterplot(x = data['MOBILE_LOGINS'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'g')\n",
    "plt.xlabel('MOBILE LOGINS')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#####\n",
    "#####\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.scatterplot(x = data['WEEKLY_PLAN'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'g')\n",
    "plt.xlabel('WEEKLY PLAN')\n",
    "           \n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.scatterplot(x = data['EARLY_DELIVERIES'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'y')\n",
    "plt.xlabel('EARLY DELIVERIES')\n",
    "\n",
    "#####           \n",
    "           \n",
    "plt.subplot(2, 2, 3)\n",
    "sns.scatterplot(x = data['LATE_DELIVERIES'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'orange')\n",
    "plt.xlabel('LATE DELIVERIES')\n",
    "\n",
    "#####           \n",
    "           \n",
    "plt.subplot(2, 2, 4)\n",
    "sns.scatterplot(x = data['PACKAGE_LOCKER'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'r')\n",
    "plt.xlabel('PACKAGE LOCKER')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#####\n",
    "#####\n",
    "           \n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.scatterplot(x = data['REFRIGERATED_LOCKER'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'g')\n",
    "plt.xlabel('REFRIGERATED LOCKER')\n",
    "           \n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.scatterplot(x = data['FOLLOWED_RECOMMENDATIONS_PCT'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'y')\n",
    "plt.xlabel('FOLLOWED RECOMMENDATIONS PCT')\n",
    "\n",
    "#####           \n",
    "           \n",
    "plt.subplot(2, 2, 3)\n",
    "sns.scatterplot(x = data['AVG_PREP_VID_TIME'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'orange')\n",
    "plt.xlabel('AVG PREP VID TIME')\n",
    "\n",
    "#####           \n",
    "           \n",
    "plt.subplot(2, 2, 4)\n",
    "sns.scatterplot(x = data['LARGEST_ORDER_SIZE'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'r')\n",
    "plt.xlabel('LARGEST ORDER SIZE')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#####\n",
    "#####\n",
    "           \n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.scatterplot(x = data['MASTER_CLASSES_ATTENDED'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'g')\n",
    "plt.xlabel('MASTER_CLASSES_ATTENDED')\n",
    "           \n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.scatterplot(x = data['MEDIAN_MEAL_RATING'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'y')\n",
    "plt.xlabel('MEDIAN_MEAL_RATING')\n",
    "\n",
    "#####           \n",
    "           \n",
    "plt.subplot(2, 2, 3)\n",
    "sns.scatterplot(x = data['AVG_CLICKS_PER_VISIT'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'orange')\n",
    "plt.xlabel('AVG_CLICKS_PER_VISIT')\n",
    "\n",
    "#####           \n",
    "           \n",
    "plt.subplot(2, 2, 4)\n",
    "sns.scatterplot(x = data['TOTAL_PHOTOS_VIEWED'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'r')\n",
    "plt.xlabel('TOTAL_PHOTOS_VIEWED')\n",
    "plt.savefig('REVENUE__PER_MEAL.png')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#####\n",
    "#####\n",
    "           \n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.scatterplot(x = data['price_per_meal'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'g')\n",
    "plt.xlabel('PRICE PER MEAL')\n",
    "plt.savefig('Housing Data Scatterplots 4 of 5.png')\n",
    "           \n",
    "#####\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.scatterplot(x = data['domain_type__junk'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'y')\n",
    "plt.xlabel('JUNK')\n",
    "\n",
    "#####           \n",
    "           \n",
    "plt.subplot(2, 2, 3)\n",
    "sns.scatterplot(x = data['domain_type__personal'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'orange')\n",
    "plt.xlabel('PERSONAL')\n",
    "\n",
    "#####           \n",
    "           \n",
    "plt.subplot(2, 2, 4)\n",
    "sns.scatterplot(x = data['domain_type__professional'],\n",
    "                y = data['REVENUE'],\n",
    "                color = 'r')\n",
    "plt.xlabel('PROFESSIONAL')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : Set Trend-Based Thresholds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trend changes *below/above* these points \n",
    "TOTAL_MEALS_ORDERED_hi = 150 \n",
    "UNIQUE_MEALS_PURCH_hi = 9 \n",
    "CONTACTS_W_CUSTOMER_SERVICE_hi = 10 \n",
    "AVG_TIME_PER_SITE_VISIT_hi = 300 \n",
    "CANCELLATIONS_BEFORE_NOON_hi = 6 \n",
    "CANCELLATIONS_AFTER_NOON_hi = 2 \n",
    "PC_LOGINS_lo = 5  \n",
    "PC_LOGINS_hi = 6 \n",
    "MOBILE_LOGINS_lo = 1\n",
    "MOBILE_LOGINS_hi = 2\n",
    "WEEKLY_PLAN_hi = 15 \n",
    "EARLY_DELIVERIES_hi = 5 \n",
    "LATE_DELIVERIES_hi = 10 \n",
    "FOLLOWED_RECOMMENDATIONS_PCT_hi = 80 \n",
    "AVG_PREP_VID_TIME_hi = 280 \n",
    "LARGEST_ORDER_SIZE_hi = 8 \n",
    "MASTER_CLASSES_ATTENDED_hi = 2 \n",
    "MEDIAN_MEAL_RATING_hi = 3 \n",
    "AVG_CLICKS_PER_VISIT_hi = 10\n",
    "TOTAL_PHOTOS_VIEWED_hi = 400\n",
    "PRICE_PER_MEAL_hi = 50\n",
    "\n",
    "## Trend changes *at* these points \n",
    "UNIQUE_MEALS_PURCH_at = 1 \n",
    "PRODUCT_CATEGORIES_VIEWED_at= 5\n",
    "MOBILE_NUMBER_at = 1 \n",
    "WEEKLY_PLAN_at = 0\n",
    "TOTAL_PHOTOS_VIEWED_at = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : Create new columns with trend-based thresholds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL_MEALS_ORDERED\n",
    "data['trend_TOTAL_MEALS_ORDERED'] = 0\n",
    "condition_hi = data.loc[0:,'trend_TOTAL_MEALS_ORDERED'][data['TOTAL_MEALS_ORDERED'] > TOTAL_MEALS_ORDERED_hi]\n",
    "\n",
    "data['trend_TOTAL_MEALS_ORDERED'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# UNIQUE_MEALS_PURCH\n",
    "data['trend_UNIQUE_MEALS_PURCH'] = 0\n",
    "condition_hi = data.loc[0:,'trend_UNIQUE_MEALS_PURCH'][data['UNIQUE_MEALS_PURCH'] > UNIQUE_MEALS_PURCH_hi]\n",
    "\n",
    "data['trend_UNIQUE_MEALS_PURCH'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# CONTACTS_W_CUSTOMER_SERVICE\n",
    "data['trend_CONTACTS_W_CUSTOMER_SERVICE'] = 0\n",
    "condition_hi = data.loc[0:,'trend_CONTACTS_W_CUSTOMER_SERVICE'][data['CONTACTS_W_CUSTOMER_SERVICE'] > CONTACTS_W_CUSTOMER_SERVICE_hi]\n",
    "\n",
    "data['trend_CONTACTS_W_CUSTOMER_SERVICE'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# AVG_TIME_PER_SITE_VISIT\n",
    "data['trend_AVG_TIME_PER_SITE_VISIT'] = 0\n",
    "condition_hi = data.loc[0:,'trend_AVG_TIME_PER_SITE_VISIT'][data['AVG_TIME_PER_SITE_VISIT'] > AVG_TIME_PER_SITE_VISIT_hi]\n",
    "\n",
    "data['trend_AVG_TIME_PER_SITE_VISIT'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# CANCELLATIONS_BEFORE_NOON\n",
    "data['trend_CANCELLATIONS_BEFORE_NOON'] = 0\n",
    "condition_hi = data.loc[0:,'trend_CANCELLATIONS_BEFORE_NOON'][data['CANCELLATIONS_BEFORE_NOON'] > CANCELLATIONS_BEFORE_NOON_hi]\n",
    "\n",
    "data['trend_CANCELLATIONS_BEFORE_NOON'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# CANCELLATIONS_AFTER_NOON\n",
    "data['trend_CANCELLATIONS_AFTER_NOON'] = 0\n",
    "condition_hi = data.loc[0:,'trend_CANCELLATIONS_AFTER_NOON'][data['CANCELLATIONS_AFTER_NOON'] > CANCELLATIONS_AFTER_NOON_hi]\n",
    "\n",
    "data['trend_CANCELLATIONS_AFTER_NOON'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# PC_LOGINS\n",
    "data['trend_PC_LOGINS'] = 0\n",
    "condition_hi = data.loc[0:,'trend_PC_LOGINS'][data['PC_LOGINS'] > PC_LOGINS_hi]\n",
    "condition_lo = data.loc[0:,'trend_PC_LOGINS'][data['PC_LOGINS'] < PC_LOGINS_lo]\n",
    "\n",
    "data['trend_PC_LOGINS'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "data['trend_PC_LOGINS'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# MOBILE_LOGINS\n",
    "data['trend_MOBILE_LOGINS'] = 0\n",
    "condition_hi = data.loc[0:,'trend_MOBILE_LOGINS'][data['MOBILE_LOGINS'] > MOBILE_LOGINS_hi]\n",
    "condition_lo = data.loc[0:,'trend_MOBILE_LOGINS'][data['MOBILE_LOGINS'] < MOBILE_LOGINS_lo]\n",
    "\n",
    "data['trend_MOBILE_LOGINS'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "data['trend_MOBILE_LOGINS'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "# WEEKLY_PLAN\n",
    "data['trend_WEEKLY_PLAN'] = 0\n",
    "condition_hi = data.loc[0:,'trend_WEEKLY_PLAN'][data['WEEKLY_PLAN'] > WEEKLY_PLAN_hi]\n",
    "\n",
    "data['trend_WEEKLY_PLAN'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "# EARLY_DELIVERIES\n",
    "data['trend_EARLY_DELIVERIES'] = 0\n",
    "condition_hi = data.loc[0:,'trend_EARLY_DELIVERIES'][data['EARLY_DELIVERIES'] > EARLY_DELIVERIES_hi]\n",
    "\n",
    "data['trend_EARLY_DELIVERIES'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "\n",
    "# LATE_DELIVERIES\n",
    "data['trend_LATE_DELIVERIES'] = 0\n",
    "condition_hi = data.loc[0:,'trend_LATE_DELIVERIES'][data['LATE_DELIVERIES'] > LATE_DELIVERIES_hi]\n",
    "\n",
    "data['trend_LATE_DELIVERIES'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# FOLLOWED_RECOMMENDATIONS_PCT\n",
    "data['trend_FOLLOWED_RECOMMENDATIONS_PCT'] = 0\n",
    "condition_hi = data.loc[0:,'trend_FOLLOWED_RECOMMENDATIONS_PCT'][data['FOLLOWED_RECOMMENDATIONS_PCT'] > FOLLOWED_RECOMMENDATIONS_PCT_hi]\n",
    "\n",
    "data['trend_FOLLOWED_RECOMMENDATIONS_PCT'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# AVG_PREP_VID_TIME\n",
    "data['trend_AVG_PREP_VID_TIME'] = 0\n",
    "condition_hi = data.loc[0:,'trend_AVG_PREP_VID_TIME'][data['AVG_PREP_VID_TIME'] > AVG_PREP_VID_TIME_hi]\n",
    "\n",
    "data['trend_AVG_PREP_VID_TIME'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "\n",
    "# LARGEST_ORDER_SIZE\n",
    "data['trend_LARGEST_ORDER_SIZE'] = 0\n",
    "condition_hi = data.loc[0:,'trend_LARGEST_ORDER_SIZE'][data['LARGEST_ORDER_SIZE'] > LARGEST_ORDER_SIZE_hi]\n",
    "\n",
    "data['trend_LARGEST_ORDER_SIZE'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "# MASTER_CLASSES_ATTENDED\n",
    "data['trend_MASTER_CLASSES_ATTENDED'] = 0\n",
    "condition_hi = data.loc[0:,'trend_MASTER_CLASSES_ATTENDED'][data['MASTER_CLASSES_ATTENDED'] > MASTER_CLASSES_ATTENDED_hi]\n",
    "\n",
    "data['trend_MASTER_CLASSES_ATTENDED'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# MEDIAN_MEAL_RATING\n",
    "data['trend_MEDIAN_MEAL_RATING'] = 0\n",
    "condition_hi = data.loc[0:,'trend_MEDIAN_MEAL_RATING'][data['MEDIAN_MEAL_RATING'] > MEDIAN_MEAL_RATING_hi]\n",
    "\n",
    "data['trend_MEDIAN_MEAL_RATING'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "# AVG_CLICKS_PER_VISIT\n",
    "data['trend_AVG_CLICKS_PER_VISIT'] = 0\n",
    "condition_hi = data.loc[0:,'trend_AVG_CLICKS_PER_VISIT'][data['AVG_CLICKS_PER_VISIT'] > AVG_CLICKS_PER_VISIT_hi]\n",
    "\n",
    "data['trend_AVG_CLICKS_PER_VISIT'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "# TOTAL_PHOTOS_VIEWED\n",
    "data['trend_TOTAL_PHOTOS_VIEWED'] = 0\n",
    "condition_hi = data.loc[0:,'trend_TOTAL_PHOTOS_VIEWED'][data['TOTAL_PHOTOS_VIEWED'] > TOTAL_PHOTOS_VIEWED_hi]\n",
    "\n",
    "data['trend_TOTAL_PHOTOS_VIEWED'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# PRICE_PER_MEAL\n",
    "data['trend_PRICE_PER_MEAL'] = 0\n",
    "condition_hi = data.loc[0:,'trend_PRICE_PER_MEAL'][data['price_per_meal'] > PRICE_PER_MEAL_hi]\n",
    "\n",
    "data['trend_PRICE_PER_MEAL'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# UNIQUE_MEALS_PURCH\n",
    "data['trend_UNIQUE_MEALS_PURCH_at'] = 0\n",
    "condition = data.loc[0:,'trend_UNIQUE_MEALS_PURCH_at'][data['UNIQUE_MEALS_PURCH'] == UNIQUE_MEALS_PURCH_at]\n",
    "\n",
    "data['trend_UNIQUE_MEALS_PURCH_at'].replace(to_replace = condition,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# PRODUCT_CATEGORIES_VIEWED\n",
    "data['trend_PRODUCT_CATEGORIES_VIEWED_at'] = 0\n",
    "condition = data.loc[0:,'trend_PRODUCT_CATEGORIES_VIEWED_at'][data['PRODUCT_CATEGORIES_VIEWED'] == PRODUCT_CATEGORIES_VIEWED_at]\n",
    "\n",
    "data['trend_PRODUCT_CATEGORIES_VIEWED_at'].replace(to_replace = condition,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# MOBILE_NUMBER\n",
    "data['trend_MOBILE_NUMBER_at'] = 0\n",
    "condition = data.loc[0:,'trend_MOBILE_NUMBER_at'][data['MOBILE_NUMBER'] == MOBILE_NUMBER_at]\n",
    "\n",
    "data['trend_MOBILE_NUMBER_at'].replace(to_replace = condition,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# WEEKLY_PLAN\n",
    "data['trend_WEEKLY_PLAN_at'] = 0\n",
    "condition = data.loc[0:,'trend_WEEKLY_PLAN_at'][data['WEEKLY_PLAN'] == WEEKLY_PLAN_at]\n",
    "\n",
    "data['trend_WEEKLY_PLAN_at'].replace(to_replace = condition,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "\n",
    "# TOTAL_PHOTOS_VIEWED\n",
    "data['trend_TOTAL_PHOTOS_VIEWED_at'] = 0\n",
    "condition = data.loc[0:,'trend_TOTAL_PHOTOS_VIEWED_at'][data['TOTAL_PHOTOS_VIEWED'] == TOTAL_PHOTOS_VIEWED_at]\n",
    "\n",
    "data['trend_TOTAL_PHOTOS_VIEWED_at'].replace(to_replace = condition,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis \n",
    "<b> Explore correlations between all explanatory variables vs. REVENUE </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Create a (Pearson) correlation matrix\n",
    "data_correlation= data.corr().round(2)\n",
    "\n",
    "\n",
    "# Print orrelations with 'REVENUE'\n",
    "print(data_correlation.loc['REVENUE'].sort_values(ascending = False).head(20))\n",
    "\n",
    "\n",
    "print(\n",
    "\"\"\"\n",
    "\n",
    "Findings\n",
    "- AVG_PREP_VID_TIME, MEDIAN_MEAL_RATING, TOTAL_MEALS_ORDERED,trend_MEDIAN_MEAL_RATING \n",
    "  have relatively high positive correlations (>50) with REVENUE\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Use OLS Regression Results to determine if there are any statistically valuable outputs (like p-value)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of 'data' so that it won't change the original data \n",
    "data_exp = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping REVENUE, NAME, EMAIL, FIRST_NAME, FAMILY_NAME, out_REVENUE from the explanatory variable set\n",
    "data_exp = data_exp.drop(['REVENUE', 'NAME', 'EMAIL', 'FIRST_NAME', 'FAMILY_NAME','out_REVENUE'], axis=1)\n",
    "\n",
    "\n",
    "# formatting each explanatory variable for statsmodels\n",
    "for val in data_exp:\n",
    "    print(f\"data['{val}'] +\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create OLS models\n",
    "\n",
    "lm_full = smf.ols(formula = \"\"\" data['REVENUE'] ~\n",
    "data['CROSS_SELL_SUCCESS'] +\n",
    "data['TOTAL_MEALS_ORDERED'] +\n",
    "data['UNIQUE_MEALS_PURCH'] +\n",
    "data['CONTACTS_W_CUSTOMER_SERVICE'] +\n",
    "data['PRODUCT_CATEGORIES_VIEWED'] +\n",
    "data['AVG_TIME_PER_SITE_VISIT'] +\n",
    "data['MOBILE_NUMBER'] +\n",
    "data['CANCELLATIONS_BEFORE_NOON'] +\n",
    "data['CANCELLATIONS_AFTER_NOON'] +\n",
    "data['TASTES_AND_PREFERENCES'] +\n",
    "data['PC_LOGINS'] +\n",
    "data['MOBILE_LOGINS'] +\n",
    "data['WEEKLY_PLAN'] +\n",
    "data['EARLY_DELIVERIES'] +\n",
    "data['LATE_DELIVERIES'] +\n",
    "data['PACKAGE_LOCKER'] +\n",
    "data['REFRIGERATED_LOCKER'] +\n",
    "data['FOLLOWED_RECOMMENDATIONS_PCT'] +\n",
    "data['AVG_PREP_VID_TIME'] +\n",
    "data['LARGEST_ORDER_SIZE'] +\n",
    "data['MASTER_CLASSES_ATTENDED'] +\n",
    "data['MEDIAN_MEAL_RATING'] +\n",
    "data['AVG_CLICKS_PER_VISIT'] +\n",
    "data['TOTAL_PHOTOS_VIEWED'] +\n",
    "data['price_per_meal'] +\n",
    "data['domain_type__junk'] +\n",
    "data['domain_type__personal'] +\n",
    "data['domain_type__professional'] +\n",
    "data['out_TOTAL_MEALS_ORDERED'] +\n",
    "data['out_CONTACTS_W_CUSTOMER_SERVICE'] +\n",
    "data['out_AVG_TIME_PER_SITE_VISIT'] +\n",
    "data['out_CANCELLATIONS_BEFORE_NOON'] +\n",
    "data['out_CANCELLATIONS_AFTER_NOON'] +\n",
    "data['out_PC_LOGINS'] +\n",
    "data['out_MOBILE_LOGINS'] +\n",
    "data['out_WEEKLY_PLAN'] +\n",
    "data['out_EARLY_DELIVERIES'] +\n",
    "data['out_LATE_DELIVERIES'] +\n",
    "data['out_FOLLOWED_RECOMMENDATIONS_PCT'] +\n",
    "data['out_MASTER_CLASSES_ATTENDED'] +\n",
    "data['out_MEDIAN_MEAL_RATING'] +\n",
    "data['out_AVG_PREP_VID_TIME'] +\n",
    "data['out_LARGEST_ORDER_SIZE'] +\n",
    "data['out_AVG_CLICKS_PER_VISIT'] +\n",
    "data['out_TOTAL_PHOTOS_VIEWED'] +\n",
    "data['out_PRICE_PER_MEAL'] +\n",
    "data['out_REFRIGERATED_LOCKER'] +\n",
    "data['trend_TOTAL_MEALS_ORDERED'] +\n",
    "data['trend_UNIQUE_MEALS_PURCH'] +\n",
    "data['trend_CONTACTS_W_CUSTOMER_SERVICE'] +\n",
    "data['trend_AVG_TIME_PER_SITE_VISIT'] +\n",
    "data['trend_CANCELLATIONS_BEFORE_NOON'] +\n",
    "data['trend_CANCELLATIONS_AFTER_NOON'] +\n",
    "data['trend_PC_LOGINS'] +\n",
    "data['trend_MOBILE_LOGINS'] +\n",
    "data['trend_WEEKLY_PLAN'] +\n",
    "data['trend_EARLY_DELIVERIES'] +\n",
    "data['trend_LATE_DELIVERIES'] +\n",
    "data['trend_FOLLOWED_RECOMMENDATIONS_PCT'] +\n",
    "data['trend_AVG_PREP_VID_TIME'] +\n",
    "data['trend_LARGEST_ORDER_SIZE'] +\n",
    "data['trend_MASTER_CLASSES_ATTENDED'] +\n",
    "data['trend_MEDIAN_MEAL_RATING'] +\n",
    "data['trend_AVG_CLICKS_PER_VISIT'] +\n",
    "data['trend_TOTAL_PHOTOS_VIEWED'] +\n",
    "data['trend_PRICE_PER_MEAL'] +\n",
    "data['trend_UNIQUE_MEALS_PURCH_at'] +\n",
    "data['trend_PRODUCT_CATEGORIES_VIEWED_at'] +\n",
    "data['trend_MOBILE_NUMBER_at'] +\n",
    "data['trend_WEEKLY_PLAN_at'] +\n",
    "data['trend_TOTAL_PHOTOS_VIEWED_at']\"\"\", data = data_exp)\n",
    "\n",
    "results = lm_full.fit()\n",
    "\n",
    "\n",
    "# printing the results\n",
    "results.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Models\n",
    "<br>\n",
    "I tried multiple models to determine the best model that generates the highest R-squared.\n",
    "\n",
    "- Linear Regression \n",
    "- Ridge Regression \n",
    "- Lasso Regression\n",
    "- K-Nearest Neighbors Regression\n",
    "- Linear Regression with standardized data \n",
    "- Ridge Regression with standardized data  \n",
    "- Lasso Regression with standardized data \n",
    "- K-Nearest Neighbors Regression with standardized data \n",
    "- Gradient Boosting Regressor \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training and testing datasets \n",
    "I dropped \"REVENUE\" and all columns whose data type was object to prepare explanatory variable data because it cannot contain targeting column or non-numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare explanatory variable data\n",
    "data_exp = data.drop(['REVENUE', 'NAME', 'EMAIL', 'FIRST_NAME', 'FAMILY_NAME', 'out_REVENUE'], axis=1)\n",
    "\n",
    "# preparing response variable data\n",
    "data_target = data.loc[:, 'REVENUE']\n",
    "\n",
    "\n",
    "# preparing training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            data_exp, # this is explanatory variable data\n",
    "            data_target, # this is response variable data\n",
    "            test_size = 0.25,\n",
    "            random_state = 222)\n",
    "\n",
    "\n",
    "# Training set \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# Testing set\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "- Training Score : 0.857\n",
    "- Testing Score : 0.837"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Fit to the training data\n",
    "lr_fit = lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predict on new data\n",
    "lr_pred = lr_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# Score the results\n",
    "print('Training Score:', lr.score(X_train, y_train).round(3))\n",
    "print('Testing Score:',  lr.score(X_test, y_test).round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression\n",
    "\n",
    "- Training Score : 0.857\n",
    "- Testing Score : 0.837\n",
    "\n",
    "I got exactly the same results as linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "ridge_model = sklearn.linear_model.Ridge()\n",
    "\n",
    "# Fit the training data\n",
    "ridge_fit  = ridge_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predict on new data\n",
    "ridge_pred = ridge_fit.predict(X_test)\n",
    "\n",
    "print('Training Score:', ridge_model.score(X_train, y_train).round(3))\n",
    "print('Testing Score:',  ridge_model.score(X_test, y_test).round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression \n",
    "\n",
    "- Training Score : 0.855\n",
    "- Testing Score : 0.838\n",
    "\n",
    "Slightly worse score on training sets, but a little better on testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression - shrinks coefficients down to zero \n",
    "\n",
    "lasso_model = sklearn.linear_model.Lasso()\n",
    "\n",
    "# FITTING the training data\n",
    "lasso_fit = lasso_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "lasso_pred = lasso_fit.predict(X_test)\n",
    "\n",
    "print('Training Score:', lasso_model.score(X_train, y_train).round(3))\n",
    "print('Testing Score:',  lasso_model.score(X_test, y_test).round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors Regressor with optimal number of neighbors 8\n",
    "\n",
    "- Training Score: 0.7333\n",
    "- Testing Score: 0.6438"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "\n",
    "# Build a visualization of 1 to 50 neighbors\n",
    "neighbors_settings = range(1, 21)\n",
    "\n",
    "\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # Building the model\n",
    "    clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Recording the training set accuracy\n",
    "    training_accuracy.append(clf.score(X_train, y_train))\n",
    "    \n",
    "    # Recording the generalization accuracy\n",
    "    test_accuracy.append(clf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "# Plot the visualization\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plt.plot(neighbors_settings, training_accuracy, label = \"training accuracy\")\n",
    "plt.plot(neighbors_settings, test_accuracy, label = \"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Finds the optimal number of neighbors\n",
    "opt_neighbors = test_accuracy.index(max(test_accuracy)) + 1\n",
    "print(f\"\"\"The optimal number of neighbors is {opt_neighbors}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a model with the optimal number of neighbors\n",
    "knn_opt = KNeighborsRegressor(algorithm = 'auto',\n",
    "                              n_neighbors = opt_neighbors)\n",
    "\n",
    "\n",
    "\n",
    "# FITTING the model based on the training data\n",
    "knn_opt.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# PREDITCING on new data\n",
    "knn_opt_pred = knn_opt.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training Score:', knn_opt.score(X_train, y_train).round(3))\n",
    "print('Testing Score:',  knn_opt.score(X_test, y_test).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# Fit the scaler with data_exp\n",
    "scaler.fit(data_exp)\n",
    "\n",
    "\n",
    "# Transform our data after fit\n",
    "X_scaled = scaler.transform(data_exp)\n",
    "\n",
    "\n",
    "# Convert scaled data into a DataFrame\n",
    "X_scaled_data = pd.DataFrame(X_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression with Standardized data\n",
    "\n",
    "- Training Score : 0.857\n",
    "- Testing Score : 0.837\n",
    "\n",
    "It does not make any difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training and testing sets with standardized data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_scaled_data, # this is explanatory variable data\n",
    "            data_target, # this is response variable data\n",
    "            test_size = 0.25,\n",
    "            random_state = 222) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "lr_fit = lr.fit(X_train, y_train)\n",
    "\n",
    "lr_pred = lr_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# Score the results\n",
    "print('Training Score:', lr.score(X_train, y_train).round(3))\n",
    "print('Testing Score:',  lr.score(X_test, y_test).round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression with standardized data\n",
    "\n",
    "- Training Score : 0.857\n",
    "- Testing Score : 0.837\n",
    "\n",
    "No difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = sklearn.linear_model.Ridge()\n",
    "\n",
    "# Fit the training data\n",
    "ridge_fit  = ridge_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predict on new data\n",
    "ridge_pred = ridge_fit.predict(X_test)\n",
    "\n",
    "print('Training Score:', ridge_model.score(X_train, y_train).round(3))\n",
    "print('Testing Score:',  ridge_model.score(X_test, y_test).round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression with standardized data\n",
    "\n",
    "- Training : 0.856\n",
    "- Testing : 0.837\n",
    "\n",
    "Slightly worse than the model with original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression - shrinks coefficients down to zero \n",
    "\n",
    "lasso_model = sklearn.linear_model.Lasso()\n",
    "\n",
    "# FITTING the training data\n",
    "lasso_fit = lasso_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "lasso_pred = lasso_fit.predict(X_test)\n",
    "\n",
    "print('Training Score:', lasso_model.score(X_train, y_train).round(3))\n",
    "print('Testing Score:',  lasso_model.score(X_test, y_test).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsRegressor with optimal number of neighbors 8\n",
    "\n",
    "- Training Score: 0.688\n",
    "- Testing Score: 0.57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating lists for training set accuracy and test set accuracy\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "\n",
    "# building a visualization of 1 to 50 neighbors\n",
    "neighbors_settings = range(1, 21)\n",
    "\n",
    "\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # Building the model\n",
    "    clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Recording the training set accuracy\n",
    "    training_accuracy.append(clf.score(X_train, y_train))\n",
    "    \n",
    "    # Recording the generalization accuracy\n",
    "    test_accuracy.append(clf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "# finding the optimal number of neighbors\n",
    "opt_neighbors = test_accuracy.index(max(test_accuracy)) + 1\n",
    "print(f\"\"\"The optimal number of neighbors is {opt_neighbors}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a model with the optimal number of neighbors\n",
    "knn_stand = KNeighborsRegressor(algorithm = 'auto',\n",
    "                   n_neighbors = opt_neighbors)\n",
    "\n",
    "\n",
    "\n",
    "# FITTING the model based on the training data\n",
    "knn_stand.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# PREDITCING on new data\n",
    "knn_stand_pred = knn_stand.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training Score:', knn_stand.score(X_train, y_train).round(3))\n",
    "print('Testing Score:',  knn_stand.score(X_test, y_test).round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor\n",
    "\n",
    "- Training Score: 1.0\n",
    "- Testing Score: 0.974\n",
    "\n",
    "Best accuracy among all the models I have tried so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            data_exp, # this is explanatory variable data\n",
    "            data_target, # this is response variable data\n",
    "            test_size = 0.25,\n",
    "            random_state = 222)\n",
    "\n",
    "\n",
    "gbr = GradientBoostingRegressor(n_estimators = 1000,min_samples_split = 3,max_depth = 3, random_state = 222)\n",
    "\n",
    "# Fit the training data\n",
    "\n",
    "gbr.fit(X_train,y_train)\n",
    "\n",
    "# Predict on new data\n",
    "y_pred = gbr.predict(X_test)\n",
    "\n",
    "print('GradientBoost Model Training Score:', gbr.score(X_train, y_train).round(3))\n",
    "print('GradientBoost Model Testing Score:',  gbr.score(X_test, y_test).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE (Root Mean Square Error) score with the gradient boosting regressor : 188.82\n",
    "\n",
    "This is less than 10% of the mean of REVENUE = the model is good enough\n",
    "\n",
    "NOTE:\n",
    "- RMSE can be interpreted as the standard deviation of the unexplained variance\n",
    "- Lower values of RMSE indicate better fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Compute MSE\n",
    "mse_test = MSE(y_test, y_pred)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse_test = mse_test ** (1/2)\n",
    "\n",
    "# Print RMSE\n",
    "print(mse_test)\n",
    "print(rmse_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
